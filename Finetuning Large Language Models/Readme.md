# [Finetuning Large Language Models](https://www.deeplearning.ai/short-courses/finetuning-large-language-models/)

## What you’ll learn in this course

Join our new short course, Finetuning Large Language Models! Learn from Sharon Zhou, Co-Founder and CEO of Lamini, and instructor for the [GANs Specialization](https://www.deeplearning.ai/courses/generative-adversarial-networks-gans-specialization/) and [How Diffusion Models Work](https://www.deeplearning.ai/short-courses/how-diffusion-models-work/).

When you complete this course, you will be able to:

- Understand when to apply finetuning on LLMs
- Prepare your data for finetuning
- Train and evaluate an LLM on your data

With finetuning, you’re able to take your own data to train the model on it, and update the weights of the neural nets in the LLM, changing the model compared to other methods like prompt engineering and Retrieval Augmented Generation. Finetuning allows the model to learn style, form, and can update the model with new knowledge to improve results.

## Who should join?
Learners who want to understand the techniques and applications of finetuning, with Python familiarity, and an understanding of a deep learning framework such as PyTorch.

## Sharon Zhou | Instructor | Co-Founder and CEO of Lamini 
- [LinkedIn](https://www.linkedin.com/in/zhousharon)
- [Twitter](https://www.twitter.com/realSharonZhou)
- [Website](https://www.lamini.ai/?utm_source=deeplearning.ai&utm_medium=referral&utm_campaign=course_finetuning)

## Reference
- [Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning](https://arxiv.org/pdf/2303.15647.pdf)
